{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Extension de tipos de datos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas se construyó originalmente sobre las capacidades presentes en NumPy, una librería de cálculo de arrays utilizada principalmente para trabajar con datos numéricos. Muchos conceptos de pandas, como los datos que faltan, se implementaron utilizando lo que estaba disponible en NumPy mientras se intentaba maximizar la compatibilidad entre las bibliotecas que utilizaban conjuntamente NumPy y Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basarse en NumPy conllevó una serie de deficiencias, como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El manejo de datos faltantes para algunos tipos de datos numéricos, como enteros y booleanos, era incompleto. Como resultado, cuando se introducían datos perdidos en tales datos, pandas convertía el tipo de datos a float64 y utilizaba np.nan para representar valores nulos. Esto tenía efectos agravantes al introducir problemas sutiles en muchos algoritmos de pandas.\n",
    "\n",
    "Los conjuntos de datos con muchos datos de cadenas eran costosos computacionalmente y utilizaban mucha memoria.\n",
    "\n",
    "Algunos tipos de datos, como intervalos de tiempo, timedeltas, y timestamps con zonas horarias, no podían ser soportados eficientemente sin usar arrays de objetos Python computacionalmente caros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más recientemente, pandas ha desarrollado un sistema de tipos de extensión que permite añadir nuevos tipos de datos aunque no estén soportados nativamente por NumPy. Estos nuevos tipos de datos pueden ser tratados como de primera clase junto con los datos procedentes de arrays NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un ejemplo en el que creamos una Serie de enteros con un valor perdido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    3.0\n",
       "3    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3, None])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_2 = pd.Series([1,2,3])\n",
    "s_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto, pandas tratará de inferir el tipo de datos de la serie.\n",
    "Dado que hay un `None` en la lista, pandas convertirá automáticamente el tipo de datos a float64 porque el tipo float en pandas puede manejar valores nulos (NaN), mientras que el tipo `int` tradicional no puede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principalmente por razones de retrocompatibilidad, Series utiliza el comportamiento heredado de usar un tipo de datos float64 y np.nan para el valor perdido. Podríamos crear esta Serie en su lugar usando pandas.Int64Dtype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       2\n",
       "2       3\n",
       "3    <NA>\n",
       "dtype: Int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_1 = pd.Series([1, 2, 3, None], dtype=pd.Int64Dtype())\n",
    "s_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí, especificamos explícitamente que queremos usar el tipo de datos Int64 de pandas, que es un tipo de datos de enteros que soporta valores nulos.\n",
    "Esto permite que la serie mantenga su tipo de datos como enteros (Int64), incluso con la presencia de valores nulos.\n",
    "Los valores nulos se representan con <NA>, que es un valor nulo especial compatible con el tipo Int64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Dtype()"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_1.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida `<NA>` indica que falta un valor para un array de tipo extensión. Esto utiliza el valor centinela especial `pandas.NA`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NA>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_1[3] is pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[3] is pd.NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podríamos haber utilizado la abreviatura `\"Int64\"` en lugar de `pd.Int64Dtype()` para especificar el tipo. La mayúscula es necesaria, de lo contrario será un tipo sin extensión basado en NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       2\n",
       "2       3\n",
       "3    <NA>\n",
       "dtype: Int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_3 = pd.Series([1, 2, 3, None], dtype=\"Int64\")\n",
    "s_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas también tiene un tipo de extensión especializado para datos de cadena que no utiliza arrays de objetos NumPy (requiere la biblioteca pyarrow, que puede que necesite instalar por separado):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      one\n",
       "1      two\n",
       "2     None\n",
       "3    three\n",
       "dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se = pd.Series(['one', 'two', None, 'three'])\n",
    "se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      one\n",
       "1      two\n",
       "2     <NA>\n",
       "3    three\n",
       "dtype: string"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_4 = pd.Series(['one', 'two', None, 'three'], dtype=pd.StringDtype())\n",
    "s_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos arrays de cadenas suelen utilizar mucha menos memoria y, con frecuencia, son más eficientes desde el punto de vista computacional para realizar operaciones en grandes conjuntos de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente Tabla figura una lista de algunos de los tipos de extensión disponibles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas extension data types**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BooleanDtype`: Datos booleanos anulables, utilice `\"boolean\"` al pasarlos como cadena.\n",
    "\n",
    "`CategoricalDtype`: Tipo de dato categórico, utilice `\"category\"` cuando pase como cadena\n",
    "\n",
    "`DatetimeTZDtype`: Datetime with time zone\n",
    "\n",
    "`Float32Dtype`: Coma flotante anulable 32-bit , use \"Float32\" cuando pase como cadena.\n",
    "\n",
    "`Float64Dtype`: Coma flotante anulable de 64 bits, utilice \"Float64\" al pasar como cadena.\n",
    "\n",
    "`Int8Dtype`: Entero con signo anulable de 8 bits, utilice \"Int8\" al pasarlo como cadena.\n",
    "\n",
    "`Int16Dtype`: Entero con signo anulable de 16 bits, utilice \"Int16\" al pasarlo como cadena.\n",
    "\n",
    "`Int32Dtype`: Entero con signo anulable de 32 bits, utilice \"Int32\" al pasarlo como cadena.\n",
    "\n",
    "`Int64Dtype`: Entero con signo anulable de 64 bits, utilice \"Int64\" al pasarlo como cadena.\n",
    "\n",
    "`UInt8Dtype`: Entero sin signo anulable de 8 bits, utilice \"UInt8\" al pasarlo como cadena.\n",
    "\n",
    "`UInt16Dtype`: Entero sin signo anulable de 16 bits, utilice \"UInt16\" al pasarlo como cadena.\n",
    "\n",
    "`UInt32Dtype`: Entero sin signo de 32 bits anulable, utilice \"UInt32\" al pasarlo como cadena.\n",
    "\n",
    "\n",
    "`UInt64Dtype`: Entero sin signo de 64 bits anulable, use \"UInt64\" cuando pase como cadena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tipos de extensión pueden pasarse al método Series `astype`, lo que permite convertirlos fácilmente como parte del proceso de limpieza de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>one</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>two</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>three</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A      B      C\n",
       "0  1.0    one  False\n",
       "1  2.0    two   None\n",
       "2  NaN  three  False\n",
       "3  4.0   None   True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"A\": [1, 2, None, 4],\n",
    "                   \"B\": [\"one\", \"two\", \"three\", None],\n",
    "                   \"C\": [False, None, False, True]})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"A\"] = df[\"A\"].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"B\"] = df[\"B\"].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    " df[\"C\"] = df[\"C\"].astype(\"boolean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>three</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A      B      C\n",
       "0     1    one  False\n",
       "1     2    two   <NA>\n",
       "2  <NA>  three  False\n",
       "3     4   <NA>   True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Manipulación de cadenas (string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python ha sido durante mucho tiempo un lenguaje popular de manipulación de datos en bruto, en parte debido a su facilidad de uso para el procesamiento de cadenas y texto. La mayoría de las operaciones de texto se simplifican con los métodos incorporados en el objeto string. Para la comparación de patrones y manipulaciones de texto más complejas, pueden ser necesarias expresiones regulares. Pandas se suma a la mezcla al permitirle aplicar expresiones de cadena y regulares de forma concisa en arrays enteros de datos, manejando además la molestia de los datos que faltan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos de objetos de cadena incorporados en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En muchas aplicaciones de manipulación de cadenas y scripts, los métodos de cadena incorporados son suficientes. Por ejemplo, una cadena separada por comas puede dividirse en trozos con split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', '  guido']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = \"a,b,  guido\"\n",
    "val.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`split` se combina a menudo con `strip` para recortar los espacios en blanco (incluidos los saltos de línea):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'guido']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pieces = [x.strip() for x in val.split(\",\")]\n",
    "pieces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas subcadenas (substrings) podrían concatenarse con un delimitador de dos puntos utilizando la suma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a::b::guido'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first, second, third = pieces\n",
    "first + \"::\" + second + \"::\" + third"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero éste no es un método genérico práctico. Una forma más rápida y pitónica es pasar una lista o tupla al método `join` sobre la cadena \"::\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a::b::guido'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"::\".join(pieces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otros métodos se ocupan de localizar subcadenas. Utilizar la palabra clave `in` de Python es la mejor forma de detectar una subcadena, aunque también se pueden utilizar `index` y `find`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"guido\" in val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.index(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.find(\":\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que la diferencia entre `find` e `index` es que index lanza una excepción si no se encuentra la cadena (en lugar de devolver -1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[139], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "val.index(\":\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por su parte, `count` devuelve el número de apariciones de una determinada subcadena:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.count(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`replace` sustituirá las ocurrencias de un patrón por otro. También se suele utilizar para eliminar patrones, pasando una cadena vacía:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a::b::  guido'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.replace(\",\", \"::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ab  guido'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.replace(\",\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente enlace puede encontrar mas [metodos de cadena]('https://www.w3schools.com/python/python_ref_string.asp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expresiones Regulares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las expresiones regulares proporcionan una forma flexible de buscar o hacer coincidir patrones de cadenas (a menudo más complejos) en el texto. Una expresión regular, comúnmente llamada regex, es una cadena formada según el lenguaje de expresiones regulares. El módulo `re` incorporado en Python se encarga de aplicar expresiones regulares a las cadenas; aquí daré varios ejemplos de su uso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones del módulo `re` se dividen en tres categorías: coincidencia de patrones, sustitución y división. Naturalmente, todas ellas están relacionadas; un `regex` describe un patrón a localizar en el texto, que luego puede utilizarse para muchos fines. Veamos un ejemplo sencillo: supongamos que queremos dividir una cadena con un número variable de caracteres de espacio en blanco (tabuladores, espacios y nuevas líneas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La expresión regular que describe uno o más caracteres de espacio en blanco es `\\s+`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', 'bar', 'baz', 'qux']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = \"foo    bar\\t baz  \\tqux\"\n",
    "\n",
    "re.split(r\"\\s+\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se llama a `re.split(r\"\\s+\", text)`, primero se compila la expresión regular y luego se llama a su método split sobre el texto pasado. Puede compilar la expresión regular usted mismo con `re.compile`, formando un objeto `regex` reutilizable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', 'bar', 'baz', 'qux']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = re.compile(r\"\\s+\")\n",
    "\n",
    "regex.split(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si, en cambio, desea obtener una lista de todos los patrones que coincidan con la expresión regular, puede utilizar el método `findall`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['    ', '\\t ', '  \\t']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.findall(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar escapes no deseados con \\ en una expresión regular, utilice literales de cadena sin procesar como `r\"C:\\x\"` en lugar del equivalente `\"C:\\\\x\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La creación de un objeto regex con `re.compile` es muy recomendable si se pretende aplicar la misma expresión a muchas cadenas; de este modo se ahorrarán ciclos de CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`match` y `search` están estrechamente relacionados con `findall`. Mientras que `findall` devuelve todas las coincidencias de una cadena, `search` sólo devuelve la primera coincidencia. Más rígidamente, `match` sólo encuentra coincidencias al principio de la cadena. Como ejemplo menos trivial, consideremos un bloque de texto y una expresión regular capaz de identificar la mayoría de las direcciones de correo electrónico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Dave dave@google.com\n",
    "Steve steve@gmail.com\n",
    "Rob rob@gmail.com\n",
    "Ryan ryan@yahoo.com\"\"\"\n",
    "\n",
    "pattern = r\"[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `[A-Z0-9._%+-]+`:  \n",
    "    - `[A-Z0-9._%+-]` es un conjunto de caracteres que incluye letras mayúsculas (A-Z), dígitos (0-9), y los caracteres ., _, %, +, y -.\n",
    "    - `+` indica que uno o más de estos caracteres pueden aparecer.    \n",
    "    - `@`: Un carácter de arroba literal.\n",
    "\n",
    "- `[A-Z0-9.-]+`:\n",
    "    - `[A-Z0-9.-]` es un conjunto de caracteres que incluye letras mayúsculas (A-Z), dígitos (0-9), y los caracteres . y -.\n",
    "    - `+` indica que uno o más de estos caracteres pueden aparecer.\n",
    "\n",
    "- `\\.`: Un punto literal (el \\ se usa para escapar el . ya que, en regex, el punto normalmente significa \"cualquier carácter\").\n",
    "\n",
    "- `[A-Z]{2,4}`:\n",
    "    - `[A-Z]` es un conjunto de letras mayúsculas.  \n",
    "    - `{2,4}` indica que deben aparecer de 2 a 4 de estas letras (por ejemplo, .com, .net, .info)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(pattern, flags=re.IGNORECASE)\n",
    "# re.IGNORECASE hace que la expresión regular no distinga entre mayúsculas y minúsculas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta línea compila el patrón de expresión regular en un objeto regex utilizando la función `re.compile()`. `flags=re.IGNORECASE`  hace que la búsqueda sea insensible a mayúsculas y minúsculas. Es decir, A-Z en el patrón también coincidirá con a-z."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilizando `findall` en el texto se obtiene una lista de las direcciones de correo electrónico**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dave@google.com', 'steve@gmail.com', 'rob@gmail.com', 'ryan@yahoo.com']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.findall(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`search` devuelve un objeto coincidente especial para la primera dirección de correo electrónico del texto. Para la regex anterior, el objeto coincidente sólo puede indicarnos la posición inicial y final del patrón en la cadena:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(5, 20), match='dave@google.com'>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = regex.search(text)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`span=(5, 20)`: span es un tupla que indica los índices de inicio y fin de la coincidencia en la cadena original text.\n",
    "En este caso, la subcadena que coincide comienza en el índice 5 y termina en el índice 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dave@google.com'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[m.start():m.end()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`regex.match` devuelve `None`, ya que sólo coincidirá si el patrón aparece al principio de la cadena:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(regex.match(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma similar, `sub` devolverá una nueva cadena con las ocurrencias del patrón sustituidas por una nueva cadena:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dave REDACTED\n",
      "Steve REDACTED\n",
      "Rob REDACTED\n",
      "Ryan REDACTED\n"
     ]
    }
   ],
   "source": [
    "print(regex.sub(\"REDACTED\", text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que desea encontrar direcciones de correo electrónico y, al mismo tiempo, segmentar cada dirección en sus tres componentes: nombre de usuario, nombre de dominio y sufijo de dominio. Para ello, ponga entre paréntesis las partes del patrón que desea segmentar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})\"\n",
    "\n",
    "regex = re.compile(pattern, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un objeto match producido por esta regex modificada devuelve una tupla de los componentes del patrón con su método groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wesm', 'bright', 'net')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = regex.match(\"wesm@bright.net\")\n",
    "\n",
    "m.groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`findall` devuelve una lista de tuplas cuando el patrón tiene grupos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dave', 'google', 'com'),\n",
       " ('steve', 'gmail', 'com'),\n",
       " ('rob', 'gmail', 'com'),\n",
       " ('ryan', 'yahoo', 'com')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.findall(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sub` también tiene acceso a los grupos de cada coincidencia mediante símbolos especiales como `\\1` y `\\2`. El símbolo `\\1` corresponde al primer grupo coincidente, `\\2` corresponde al segundo, y así sucesivamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dave Username: dave, Domain: google, Suffix: com\n",
      "Steve Username: steve, Domain: gmail, Suffix: com\n",
      "Rob Username: rob, Domain: gmail, Suffix: com\n",
      "Ryan Username: ryan, Domain: yahoo, Suffix: com\n"
     ]
    }
   ],
   "source": [
    "print(regex.sub(r\"Username: \\1, Domain: \\2, Suffix: \\3\", text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación algunos metodos adicionales de expresiones regulares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`findall`: Devuelve todos los patrones coincidentes no solapados en una cadena como una lista.\n",
    "\n",
    "`finditer`: Como findall, pero devuelve un iterador.\n",
    "\n",
    "`match`: \tCoincide con el patrón al inicio de la cadena y opcionalmente segmenta los componentes del patrón en grupos; si el patrón coincide, devuelve un objeto coincidente, y en caso contrario `None`.\n",
    "\n",
    "`search`: Escanea la cadena en busca de coincidencias con el patrón, devolviendo un objeto coincidente si es así; a diferencia de match, la coincidencia puede estar en cualquier parte de la cadena en lugar de sólo al principio.\n",
    "\n",
    "`split`: Rompe la cadena en trozos en cada aparición del patrón.\n",
    "\n",
    "`sub, subn`: Reemplazar todas (`sub`) o las primeras `n` ocurrencias (`subn`) del patrón en la cadena con la expresión de reemplazo; utilizar los símbolos `\\1`, `\\2`, ... para referirse a los elementos del grupo de coincidencia en la cadena de reemplazo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de cadena en pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpiar un conjunto de datos desordenado para su análisis suele requerir mucha manipulación de cadenas. Para complicar las cosas, una columna que contiene cadenas a veces tiene datos que faltan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     dave@google.com\n",
       "Steve    steve@gmail.com\n",
       "Rob        rob@gmail.com\n",
       "Wes                  NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"Dave\": \"dave@google.com\",\n",
    "        \"Steve\": \"steve@gmail.com\",\n",
    "        \"Rob\": \"rob@gmail.com\",\n",
    "        \"Wes\": np.nan}\n",
    "\n",
    "data = pd.Series(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     False\n",
       "Steve    False\n",
       "Rob      False\n",
       "Wes       True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden aplicar métodos de cadenas y expresiones regulares (pasando una `lambda` u otra función) a cada valor utilizando `data.map`, pero fallará en los valores NA (nulos). Para hacer frente a esto, Series dispone de métodos orientados a arrays para operaciones con cadenas que omiten y propagan los valores NA. Se accede a ellos a través del atributo str de Series; por ejemplo, podríamos comprobar si cada dirección de correo electrónico contiene \"gmail\" con `str.contains`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     False\n",
       "Steve     True\n",
       "Rob       True\n",
       "Wes        NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.str.contains(\"gmail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que el resultado de esta operación tiene un dtype objeto. pandas tiene tipos de extensión que proporcionan un tratamiento especializado de cadenas, enteros y datos booleanos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     dave@google.com\n",
       "Steve    steve@gmail.com\n",
       "Rob        rob@gmail.com\n",
       "Wes                 <NA>\n",
       "dtype: string"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_as_string_ext = data.astype('string')\n",
    "data_as_string_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     False\n",
       "Steve     True\n",
       "Rob       True\n",
       "Wes       <NA>\n",
       "dtype: boolean"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_as_string_ext.str.contains(\"gmail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se pueden utilizar expresiones regulares, junto con otras opciones como IGNORECASE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     [(dave, google, com)]\n",
       "Steve    [(steve, gmail, com)]\n",
       "Rob        [(rob, gmail, com)]\n",
       "Wes                        NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})\"\n",
    "data.str.findall(pattern, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede utilizar str.get o indexar en el atributo str:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     (dave, google, com)\n",
       "Steve    (steve, gmail, com)\n",
       "Rob        (rob, gmail, com)\n",
       "Wes                      NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = data.str.findall(pattern, flags=re.IGNORECASE).str[0]\n",
    "# busca todas las coincidencias del patrón en cada elemento \n",
    "# de la Serie y devuelve listas de tuplas con las coincidencias encontradas.\n",
    "# .str[0] selecciona la primera coincidencia en cada lista de coincidencias.\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches = data.str.findall(pattern, flags=re.IGNORECASE)\n",
    "# matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     google\n",
       "Steve     gmail\n",
       "Rob       gmail\n",
       "Wes         NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.str.get(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma similar, puede cortar cadenas utilizando esta sintaxis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     dave@\n",
       "Steve    steve\n",
       "Rob      rob@g\n",
       "Wes        NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.str[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `str.extract` devolverá los grupos capturados de una expresión regular como un DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>dave</td>\n",
       "      <td>google</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steve</th>\n",
       "      <td>steve</td>\n",
       "      <td>gmail</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rob</th>\n",
       "      <td>rob</td>\n",
       "      <td>gmail</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wes</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0       1    2\n",
       "Dave    dave  google  com\n",
       "Steve  steve   gmail  com\n",
       "Rob      rob   gmail  com\n",
       "Wes      NaN     NaN  NaN"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.str.extract(pattern, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente tabla se muestran otros métodos de String en Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cat`: Concatenar cadenas por elementos con un delimitador opcional\n",
    "\n",
    "`contains`: Devuelve una matriz booleana si cada cadena contiene un patrón/regex.\n",
    "\n",
    "`count`: Contar ocurrencias del patrón\n",
    "\n",
    "`extract`: Utilice una expresión regular con grupos para extraer una o varias cadenas de una serie de cadenas; el resultado será un DataFrame con una columna por grupo.\n",
    "\n",
    "`endswith`: Equivale a x.endswith(pattern) para cada elemento\n",
    "\n",
    "`startswith`: Equivale a x.startswith(pattern) para cada elemento\n",
    "\n",
    " `findall`: Calcula la lista de todas las apariciones del patrón/regex para cada cadena.\n",
    " \n",
    " `get`: Índice en cada elemento (recuperar el i-ésimo elemento)\n",
    " \n",
    " `isalnum`: Equivalente a str.alnum incorporado\n",
    " \n",
    " `isalpha`: Equivalente al built-in str.isalpha.\n",
    " \n",
    " `isdecimal`: Equivalente al built-in str.isdecimal.\n",
    "\n",
    "`isdigit`: Equivalente al built-in str.isdigit\n",
    "\n",
    "`islower`: Equivalent to built-in str.islower\n",
    "\n",
    "`isnumeric`: Equivalent to built-in str.isnumeric.\n",
    "\n",
    "`isupper`: Equivalent to built-in str.isupper.\n",
    "\n",
    "`join`: Une las cadenas de cada elemento de la Serie con el separador pasado.\n",
    "\n",
    "`len`: Calcular la longitud de cada cadena.\n",
    "\n",
    "`lower, upper` : Convertir casos; equivalente a x.lower() o x.upper() para cada elemento.\n",
    "\n",
    "`match`: Utiliza re.match con la expresión regular pasada en cada elemento, devolviendo True o False si coincide\n",
    "\n",
    "`pad`: Añadir espacios en blanco a la izquierda, a la derecha o a ambos lados de las cadenas\n",
    "\n",
    "`center`: Equivale a pad(side=\"both\")\n",
    "\n",
    "`replace`: Reemplazar las ocurrencias de un patrón/regex por otra cadena\n",
    "\n",
    "`slice`: Corta cada cadena de la serie\n",
    "\n",
    "`split` : Dividir cadenas según delimitador o expresión regular\n",
    "\n",
    "`strip`: Recorta los espacios en blanco de ambos lados, incluidas las nuevas líneas.\n",
    "\n",
    "`rstrip`: Recortar los espacios en blanco de la derecha.\n",
    "\n",
    "`lstrip`: Recortar los espacios en blanco de la izquierda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5. Expresiones regulares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dado el siguiente Diccionario:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    'Name': [\n",
    "        'Dave', 'Steve', 'Rob', 'Ryan', 'Alice', 'Eve', 'John', 'Jane', 'Peter', 'Mary', 'Tom', 'Lucy', \n",
    "        'Mike', 'Chris', 'Emma', 'Olivia', 'Sophia', 'Liam', 'Noah', 'Mason', 'Ava', 'Mia', 'James', 'Benjamin'\n",
    "    ],\n",
    "    'Email': [\n",
    "        'dave@google.com', 'steve@gmail.com', 'rob@yahoo.com', 'ryan@gmail.com', \n",
    "        'alice@hotmail.com', 'eve@google.com', 'john@outlook.com', 'jane@gmail.com',\n",
    "        'peter@amazon.com', 'mary@google.com', 'tom@apple.com', 'lucy@yahoo.com',\n",
    "        'mike@facebook.com', 'chris@netflix.com', 'emma@google.com', 'olivia@gmail.com',\n",
    "        'sophia@amazon.com', 'liam@apple.com', 'noah@google.com', 'mason@yahoo.com',\n",
    "        'ava@outlook.com', 'mia@gmail.com', 'james@hotmail.com', 'benjamin@google.com'\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una vez pasado el diccionario a un DataFrame que contiene nombres y direcciones de correo electrónico, realiza las siguientes tareas:\n",
    "\n",
    "- Extrae los dominios de los correos electrónicos.\n",
    "- Cuenta la frecuencia de cada dominio.\n",
    "- Crea un nuevo DataFrame que contenga cada dominio como columna y el número de veces que se repiten dichos dominios en las filas.\n",
    "#### Resolver de las dos formas: Usando expresiones regulares y usando los métodos propios de pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución con expresiones regulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name                Email        Domain\n",
      "0       Dave      dave@google.com    google.com\n",
      "1      Steve      steve@gmail.com     gmail.com\n",
      "2        Rob        rob@yahoo.com     yahoo.com\n",
      "3       Ryan       ryan@gmail.com     gmail.com\n",
      "4      Alice    alice@hotmail.com   hotmail.com\n",
      "5        Eve       eve@google.com    google.com\n",
      "6       John     john@outlook.com   outlook.com\n",
      "7       Jane       jane@gmail.com     gmail.com\n",
      "8      Peter     peter@amazon.com    amazon.com\n",
      "9       Mary      mary@google.com    google.com\n",
      "10       Tom        tom@apple.com     apple.com\n",
      "11      Lucy       lucy@yahoo.com     yahoo.com\n",
      "12      Mike    mike@facebook.com  facebook.com\n",
      "13     Chris    chris@netflix.com   netflix.com\n",
      "14      Emma      emma@google.com    google.com\n",
      "15    Olivia     olivia@gmail.com     gmail.com\n",
      "16    Sophia    sophia@amazon.com    amazon.com\n",
      "17      Liam       liam@apple.com     apple.com\n",
      "18      Noah      noah@google.com    google.com\n",
      "19     Mason      mason@yahoo.com     yahoo.com\n",
      "20       Ava      ava@outlook.com   outlook.com\n",
      "21       Mia        mia@gmail.com     gmail.com\n",
      "22     James    james@hotmail.com   hotmail.com\n",
      "23  Benjamin  benjamin@google.com    google.com\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Función para extraer el dominio usando expresiones regulares\n",
    "def extract_domain(email):\n",
    "    return re.search(\"@([\\w\\.]+)\", email).group(1)\n",
    "\n",
    "# Aplicamos la función a la columna 'Email'\n",
    "df['Domain'] = df['Email'].apply(extract_domain)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución con los métodos propios de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name                Email        Domain\n",
      "0       Dave      dave@google.com    google.com\n",
      "1      Steve      steve@gmail.com     gmail.com\n",
      "2        Rob        rob@yahoo.com     yahoo.com\n",
      "3       Ryan       ryan@gmail.com     gmail.com\n",
      "4      Alice    alice@hotmail.com   hotmail.com\n",
      "5        Eve       eve@google.com    google.com\n",
      "6       John     john@outlook.com   outlook.com\n",
      "7       Jane       jane@gmail.com     gmail.com\n",
      "8      Peter     peter@amazon.com    amazon.com\n",
      "9       Mary      mary@google.com    google.com\n",
      "10       Tom        tom@apple.com     apple.com\n",
      "11      Lucy       lucy@yahoo.com     yahoo.com\n",
      "12      Mike    mike@facebook.com  facebook.com\n",
      "13     Chris    chris@netflix.com   netflix.com\n",
      "14      Emma      emma@google.com    google.com\n",
      "15    Olivia     olivia@gmail.com     gmail.com\n",
      "16    Sophia    sophia@amazon.com    amazon.com\n",
      "17      Liam       liam@apple.com     apple.com\n",
      "18      Noah      noah@google.com    google.com\n",
      "19     Mason      mason@yahoo.com     yahoo.com\n",
      "20       Ava      ava@outlook.com   outlook.com\n",
      "21       Mia        mia@gmail.com     gmail.com\n",
      "22     James    james@hotmail.com   hotmail.com\n",
      "23  Benjamin  benjamin@google.com    google.com\n"
     ]
    }
   ],
   "source": [
    "# Extraer el dominio usando el método split de pandas\n",
    "df['Domain'] = df['Email'].str.split('@').str[1]\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contar la frecuencia de cada dominio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain\n",
      "google.com      6\n",
      "gmail.com       5\n",
      "yahoo.com       3\n",
      "hotmail.com     2\n",
      "outlook.com     2\n",
      "amazon.com      2\n",
      "apple.com       2\n",
      "facebook.com    1\n",
      "netflix.com     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar la frecuencia de cada dominio\n",
    "domain_counts = df['Domain'].value_counts()\n",
    "print(domain_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Nuevo DataFrame con la frecuencia de cada dominio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando expresiones regulares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Domain  Count\n",
      "0    google.com      6\n",
      "1     gmail.com      5\n",
      "2     yahoo.com      3\n",
      "3   hotmail.com      2\n",
      "4   outlook.com      2\n",
      "5    amazon.com      2\n",
      "6     apple.com      2\n",
      "7  facebook.com      1\n",
      "8   netflix.com      1\n"
     ]
    }
   ],
   "source": [
    "# Crear un nuevo DataFrame con la frecuencia de cada dominio\n",
    "domain_df = pd.DataFrame(domain_counts).reset_index()\n",
    "domain_df.columns = ['Domain', 'Count']\n",
    "print(domain_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando métodos propios de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el DataFrame con los dominios y sus cuentas\n",
    "domain_df = df['Domain'].value_counts().reset_index()\n",
    "domain_df.columns = ['Domain', 'Count']\n",
    "print(domain_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código completo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "data = {\n",
    "    'Name': [\n",
    "        'Dave', 'Steve', 'Rob', 'Ryan', 'Alice', 'Eve', 'John', 'Jane', 'Peter', 'Mary', 'Tom', 'Lucy', \n",
    "        'Mike', 'Chris', 'Emma', 'Olivia', 'Sophia', 'Liam', 'Noah', 'Mason', 'Ava', 'Mia', 'James', 'Benjamin'\n",
    "    ],\n",
    "    'Email': [\n",
    "        'dave@google.com', 'steve@gmail.com', 'rob@yahoo.com', 'ryan@gmail.com', \n",
    "        'alice@hotmail.com', 'eve@google.com', 'john@outlook.com', 'jane@gmail.com',\n",
    "        'peter@amazon.com', 'mary@google.com', 'tom@apple.com', 'lucy@yahoo.com',\n",
    "        'mike@facebook.com', 'chris@netflix.com', 'emma@google.com', 'olivia@gmail.com',\n",
    "        'sophia@amazon.com', 'liam@apple.com', 'noah@google.com', 'mason@yahoo.com',\n",
    "        'ava@outlook.com', 'mia@gmail.com', 'james@hotmail.com', 'benjamin@google.com'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extraer dominios usando expresiones regulares\n",
    "def extract_domain(email):\n",
    "    return re.search(\"@([\\w\\.]+)\", email).group(1)\n",
    "\n",
    "df['Domain_regex'] = df['Email'].apply(extract_domain)\n",
    "\n",
    "# Extraer dominios usando métodos propios de pandas\n",
    "df['Domain_pandas'] = df['Email'].str.split('@').str[1]\n",
    "\n",
    "# Contar la frecuencia de cada dominio\n",
    "domain_counts_regex = df['Domain_regex'].value_counts()\n",
    "domain_counts_pandas = df['Domain_pandas'].value_counts()\n",
    "\n",
    "# Crear DataFrame con la frecuencia de cada dominio\n",
    "domain_df_regex = pd.DataFrame(domain_counts_regex).reset_index()\n",
    "domain_df_regex.columns = ['Domain', 'Count']\n",
    "\n",
    "domain_df_pandas = pd.DataFrame(domain_counts_pandas).reset_index()\n",
    "domain_df_pandas.columns = ['Domain', 'Count']\n",
    "\n",
    "print(\"DataFrame con expresiones regulares:\")\n",
    "print(domain_df_regex)\n",
    "print(\"\\nDataFrame con métodos propios de pandas:\")\n",
    "print(domain_df_pandas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 Datos Categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     apple\n",
       "1    orange\n",
       "2     apple\n",
       "3     apple\n",
       "4     apple\n",
       "5    orange\n",
       "6     apple\n",
       "7     apple\n",
       "dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = pd.Series(['apple', 'orange', 'apple',\n",
    "                    'apple'] * 2)\n",
    "values   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['apple', 'orange'], dtype=object)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CursosTardes\\AppData\\Local\\Temp\\ipykernel_12484\\3297668723.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(values)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "apple     6\n",
       "orange    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apple     6\n",
       "orange    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(values).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchos sistemas de datos (para almacenamiento de datos, cálculo estadístico u otros usos) han desarrollado enfoques especializados para representar datos con valores repetidos para un almacenamiento y cálculo más eficientes. En el almacenamiento de datos, una práctica recomendada consiste en utilizar las denominadas tablas de dimensiones, que contienen los valores distintos y almacenan las observaciones primarias como claves enteras que hacen referencia a la tabla de dimensiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    1\n",
       "6    0\n",
       "7    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = pd.Series([0, 1, 0, 0] * 2)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     apple\n",
       "1    orange\n",
       "dtype: object"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = pd.Series(['apple', 'orange'])\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar el método `take` para restaurar la serie original de cadenas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     apple\n",
       "1    orange\n",
       "0     apple\n",
       "0     apple\n",
       "0     apple\n",
       "1    orange\n",
       "0     apple\n",
       "0     apple\n",
       "dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim.take(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta representación como números enteros se denomina representación categórica o codificada en diccionario. La array de valores distintos puede denominarse categorías, diccionario o niveles de los datos. Aqui utilizaremos los términos categórico y categorías. Los valores enteros que hacen referencia a las categorías se denominan códigos de categoría o simplemente códigos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que tenemos una serie de índices codificados que representan diferentes tipos de mascotas, y una serie de etiquetas que contienen los nombres de las mascotas. Queremos usar el método take para reconstruir las etiquetas originales a partir de los índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     cat\n",
       "1     dog\n",
       "2    bird\n",
       "1     dog\n",
       "0     cat\n",
       "2    bird\n",
       "2    bird\n",
       "0     cat\n",
       "dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Series de índices codificados\n",
    "encoded_labels = pd.Series([0, 1, 2, 1, 0, 2, 2, 0])\n",
    "\n",
    "# Series de etiquetas originales\n",
    "pet_labels = pd.Series(['cat', 'dog', 'bird'])\n",
    "\n",
    "# Reconstruir las etiquetas originales\n",
    "decoded_labels = pet_labels.take(encoded_labels)\n",
    "\n",
    "decoded_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 6. Dados los siguientes datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoded_labels = [\n",
    "    0, 1, 2, 3, 0, 4, 5, 6, 2, 1, 3, 0, 5, 4, 6, 1, 2, 5, 4, 3,\n",
    "    7, 8, 9, 10, 7, 11, 12, 13, 9, 8, 10, 7, 12, 11, 13, 8, 9, 12, 11, 10,\n",
    "    14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33\n",
    "]\n",
    "\n",
    "animal_labels = [\n",
    "    'cat', 'dog', 'bird', 'fish', 'lion', 'tiger', 'bear', 'elephant', \n",
    "    'giraffe', 'zebra', 'kangaroo', 'koala', 'panda', 'monkey',\n",
    "    'shark', 'whale', 'dolphin', 'penguin', 'ostrich', 'crocodile', \n",
    "    'alligator', 'hippopotamus', 'rhinoceros', 'cheetah', 'leopard', \n",
    "    'jaguar', 'wolf', 'fox', 'rabbit', 'squirrel', 'bat', 'owl', \n",
    "    'hawk', 'eagle'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Recrear las etiquetas originales a partir de los índices codificados.  \n",
    "2- Contar la frecuencia de cada etiqueta de animal.  \n",
    "3- Identificar las etiquetas de animales únicas presentes en los datos.  \n",
    "4- Determinar el animal más frecuente y el menos frecuente.  \n",
    "5- Agrupar los animales y contar la frecuencia por grupos (mamíferos, aves, reptiles, etc.).  \n",
    "6- Identificar la posición de las primeras y últimas ocurrencias de cada animal.  \n",
    "7- Generar un resumen estadístico de las frecuencias de los animales (media, mediana, desviación estándar).  \n",
    "8- Filtrar y mostrar solo los animales con una frecuencia mayor que 2.  \n",
    "9- Encontrar y mostrar las etiquetas de animales que aparecen solo una vez.  \n",
    "10- Calcular el porcentaje de apariciones de cada animal respecto al total.  \n",
    "11- Ordenar las etiquetas de animales por frecuencia en orden descendente.  \n",
    "12- Generar un DataFrame que muestre la frecuencia acumulativa de las etiquetas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recrear las etiquetas originales a partir de los índices codificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'dog', 'bird', 'fish', 'cat', 'lion', 'tiger', 'bear', 'bird', 'dog', 'fish', 'cat', 'tiger', 'lion', 'bear', 'dog', 'bird', 'tiger', 'lion', 'fish', 'elephant', 'giraffe', 'zebra', 'kangaroo', 'elephant', 'koala', 'panda', 'monkey', 'zebra', 'giraffe', 'kangaroo', 'elephant', 'panda', 'koala', 'monkey', 'giraffe', 'zebra', 'panda', 'koala', 'kangaroo', 'shark', 'whale', 'dolphin', 'penguin', 'ostrich', 'crocodile', 'alligator', 'hippopotamus', 'rhinoceros', 'cheetah', 'leopard', 'jaguar', 'wolf', 'fox', 'rabbit', 'squirrel', 'bat', 'owl', 'hawk', 'eagle']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Datos proporcionados\n",
    "encoded_labels = [\n",
    "    0, 1, 2, 3, 0, 4, 5, 6, 2, 1, 3, 0, 5, 4, 6, 1, 2, 5, 4, 3,\n",
    "    7, 8, 9, 10, 7, 11, 12, 13, 9, 8, 10, 7, 12, 11, 13, 8, 9, 12, 11, 10,\n",
    "    14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33\n",
    "]\n",
    "\n",
    "animal_labels = [\n",
    "    'cat', 'dog', 'bird', 'fish', 'lion', 'tiger', 'bear', 'elephant', \n",
    "    'giraffe', 'zebra', 'kangaroo', 'koala', 'panda', 'monkey',\n",
    "    'shark', 'whale', 'dolphin', 'penguin', 'ostrich', 'crocodile', \n",
    "    'alligator', 'hippopotamus', 'rhinoceros', 'cheetah', 'leopard', \n",
    "    'jaguar', 'wolf', 'fox', 'rabbit', 'squirrel', 'bat', 'owl', \n",
    "    'hawk', 'eagle'\n",
    "]\n",
    "\n",
    "# Recrear las etiquetas originales\n",
    "original_labels = [animal_labels[i] for i in encoded_labels]\n",
    "print(original_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Contar la frecuencia de cada etiqueta de animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal\n",
      "cat             3\n",
      "elephant        3\n",
      "dog             3\n",
      "panda           3\n",
      "kangaroo        3\n",
      "zebra           3\n",
      "giraffe         3\n",
      "koala           3\n",
      "tiger           3\n",
      "lion            3\n",
      "fish            3\n",
      "bird            3\n",
      "bear            2\n",
      "monkey          2\n",
      "leopard         1\n",
      "hawk            1\n",
      "owl             1\n",
      "bat             1\n",
      "squirrel        1\n",
      "rabbit          1\n",
      "fox             1\n",
      "wolf            1\n",
      "jaguar          1\n",
      "penguin         1\n",
      "cheetah         1\n",
      "rhinoceros      1\n",
      "hippopotamus    1\n",
      "alligator       1\n",
      "crocodile       1\n",
      "ostrich         1\n",
      "dolphin         1\n",
      "whale           1\n",
      "shark           1\n",
      "eagle           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame para facilitar el análisis\n",
    "df = pd.DataFrame(original_labels, columns=['Animal'])\n",
    "\n",
    "# Contar la frecuencia de cada etiqueta de animal\n",
    "frequency_counts = df['Animal'].value_counts()\n",
    "print(frequency_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identificar las etiquetas de animales únicas presentes en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat' 'dog' 'bird' 'fish' 'lion' 'tiger' 'bear' 'elephant' 'giraffe'\n",
      " 'zebra' 'kangaroo' 'koala' 'panda' 'monkey' 'shark' 'whale' 'dolphin'\n",
      " 'penguin' 'ostrich' 'crocodile' 'alligator' 'hippopotamus' 'rhinoceros'\n",
      " 'cheetah' 'leopard' 'jaguar' 'wolf' 'fox' 'rabbit' 'squirrel' 'bat' 'owl'\n",
      " 'hawk' 'eagle']\n"
     ]
    }
   ],
   "source": [
    "# Etiquetas de animales únicas\n",
    "unique_animals = df['Animal'].unique()\n",
    "print(unique_animals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Determinar el animal más frecuente y el menos frecuente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent animal: cat with 3 occurrences\n",
      "Least frequent animal: leopard with 1 occurrence\n"
     ]
    }
   ],
   "source": [
    "# Animal más frecuente\n",
    "most_frequent_animal = frequency_counts.idxmax()\n",
    "most_frequent_count = frequency_counts.max()\n",
    "print(f\"Most frequent animal: {most_frequent_animal} with {most_frequent_count} occurrences\")\n",
    "\n",
    "# Animal menos frecuente\n",
    "least_frequent_animal = frequency_counts.idxmin()\n",
    "least_frequent_count = frequency_counts.min()\n",
    "print(f\"Least frequent animal: {least_frequent_animal} with {least_frequent_count} occurrence\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agrupar los animales y contar la frecuencia por grupos (mamíferos, aves, reptiles, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Group  Count\n",
      "0   Mammals     40\n",
      "1     Birds      8\n",
      "2  Reptiles      2\n",
      "3    Others      4\n"
     ]
    }
   ],
   "source": [
    "# Definir grupos de animales\n",
    "groups = {\n",
    "    'Mammals': ['cat', 'dog', 'lion', 'tiger', 'bear', 'elephant', 'giraffe', 'zebra', \n",
    "                'kangaroo', 'koala', 'panda', 'monkey', 'dolphin', 'whale', 'wolf', \n",
    "                'fox', 'rabbit', 'squirrel'],\n",
    "    'Birds': ['bird', 'penguin', 'ostrich', 'owl', 'hawk', 'eagle'],\n",
    "    'Reptiles': ['crocodile', 'alligator'],\n",
    "    'Others': ['fish', 'shark']\n",
    "}\n",
    "\n",
    "# Contar la frecuencia por grupos\n",
    "group_counts = {group: df['Animal'].isin(members).sum() for group, members in groups.items()}\n",
    "group_counts_df = pd.DataFrame(list(group_counts.items()), columns=['Group', 'Count'])\n",
    "print(group_counts_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Identificar la posición de las primeras y últimas ocurrencias de cada animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Animal  First Occurrence  Last Occurrence\n",
      "0            cat                 0               11\n",
      "1            dog                 1               14\n",
      "2           bird                 2               15\n",
      "3           fish                 3               16\n",
      "4           lion                 5               17\n",
      "5          tiger                 6               18\n",
      "6           bear                 7               19\n",
      "7       elephant                20               31\n",
      "8        giraffe                21               34\n",
      "9          zebra                22               35\n",
      "10      kangaroo                23               36\n",
      "11         koala                25               37\n",
      "12         panda                26               38\n",
      "13        monkey                27               39\n",
      "14         shark                40               40\n",
      "15         whale                41               41\n",
      "16       dolphin                42               42\n",
      "17       penguin                43               43\n",
      "18       ostrich                44               44\n",
      "19     crocodile                45               45\n",
      "20     alligator                46               46\n",
      "21  hippopotamus                47               47\n",
      "22    rhinoceros                48               48\n",
      "23       cheetah                49               49\n",
      "24       leopard                50               50\n",
      "25        jaguar                51               51\n",
      "26          wolf                52               52\n",
      "27           fox                53               53\n",
      "28        rabbit                54               54\n",
      "29      squirrel                55               55\n",
      "30           bat                56               56\n",
      "31           owl                57               57\n",
      "32          hawk                58               58\n",
      "33         eagle                59               59\n"
     ]
    }
   ],
   "source": [
    "# Identificar primeras y últimas ocurrencias\n",
    "first_occurrences = df['Animal'].drop_duplicates().index\n",
    "last_occurrences = df.iloc[::-1]['Animal'].drop_duplicates().index[::-1]\n",
    "\n",
    "positions_df = pd.DataFrame({\n",
    "    'Animal': df['Animal'].unique(),\n",
    "    'First Occurrence': first_occurrences,\n",
    "    'Last Occurrence': last_occurrences\n",
    "})\n",
    "print(positions_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generar un resumen estadístico de las frecuencias de los animales (media, mediana, desviación estándar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     34.000000\n",
      "mean       1.764706\n",
      "std        0.955330\n",
      "min        1.000000\n",
      "25%        1.000000\n",
      "50%        1.000000\n",
      "75%        3.000000\n",
      "max        3.000000\n",
      "median     1.000000\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Resumen estadístico\n",
    "summary_stats = frequency_counts.describe()\n",
    "summary_stats['median'] = frequency_counts.median()\n",
    "summary_stats['std'] = frequency_counts.std()\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Filtrar y mostrar solo los animales con una frecuencia mayor que 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal\n",
      "cat         3\n",
      "elephant    3\n",
      "dog         3\n",
      "panda       3\n",
      "kangaroo    3\n",
      "zebra       3\n",
      "giraffe     3\n",
      "koala       3\n",
      "tiger       3\n",
      "lion        3\n",
      "fish        3\n",
      "bird        3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Animales con frecuencia mayor que 2\n",
    "animals_gt_2 = frequency_counts[frequency_counts > 2]\n",
    "print(animals_gt_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Encontrar y mostrar las etiquetas de animales que aparecen solo una vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal\n",
      "leopard         1\n",
      "hawk            1\n",
      "owl             1\n",
      "bat             1\n",
      "squirrel        1\n",
      "rabbit          1\n",
      "fox             1\n",
      "wolf            1\n",
      "jaguar          1\n",
      "penguin         1\n",
      "cheetah         1\n",
      "rhinoceros      1\n",
      "hippopotamus    1\n",
      "alligator       1\n",
      "crocodile       1\n",
      "ostrich         1\n",
      "dolphin         1\n",
      "whale           1\n",
      "shark           1\n",
      "eagle           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Animales que aparecen solo una vez\n",
    "animals_eq_1 = frequency_counts[frequency_counts == 1]\n",
    "print(animals_eq_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calcular el porcentaje de apariciones de cada animal respecto al total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Animal  Percentage\n",
      "0            cat    5.000000\n",
      "1       elephant    5.000000\n",
      "2            dog    5.000000\n",
      "3          panda    5.000000\n",
      "4       kangaroo    5.000000\n",
      "5          zebra    5.000000\n",
      "6        giraffe    5.000000\n",
      "7          koala    5.000000\n",
      "8          tiger    5.000000\n",
      "9           lion    5.000000\n",
      "10          fish    5.000000\n",
      "11          bird    5.000000\n",
      "12          bear    3.333333\n",
      "13        monkey    3.333333\n",
      "14       leopard    1.666667\n",
      "15          hawk    1.666667\n",
      "16           owl    1.666667\n",
      "17           bat    1.666667\n",
      "18      squirrel    1.666667\n",
      "19        rabbit    1.666667\n",
      "20           fox    1.666667\n",
      "21          wolf    1.666667\n",
      "22        jaguar    1.666667\n",
      "23       penguin    1.666667\n",
      "24       cheetah    1.666667\n",
      "25    rhinoceros    1.666667\n",
      "26  hippopotamus    1.666667\n",
      "27     alligator    1.666667\n",
      "28     crocodile    1.666667\n",
      "29       ostrich    1.666667\n",
      "30       dolphin    1.666667\n",
      "31         whale    1.666667\n",
      "32         shark    1.666667\n",
      "33         eagle    1.666667\n"
     ]
    }
   ],
   "source": [
    "# Porcentaje de apariciones de cada animal\n",
    "total_count = df['Animal'].count()\n",
    "percentage_counts = (frequency_counts / total_count) * 100\n",
    "percentage_counts_df = percentage_counts.reset_index()\n",
    "percentage_counts_df.columns = ['Animal', 'Percentage']\n",
    "print(percentage_counts_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Ordenar las etiquetas de animales por frecuencia en orden descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal\n",
      "cat             3\n",
      "koala           3\n",
      "elephant        3\n",
      "fish            3\n",
      "lion            3\n",
      "tiger           3\n",
      "bird            3\n",
      "giraffe         3\n",
      "zebra           3\n",
      "kangaroo        3\n",
      "panda           3\n",
      "dog             3\n",
      "bear            2\n",
      "monkey          2\n",
      "cheetah         1\n",
      "shark           1\n",
      "whale           1\n",
      "dolphin         1\n",
      "ostrich         1\n",
      "crocodile       1\n",
      "alligator       1\n",
      "hippopotamus    1\n",
      "rhinoceros      1\n",
      "bat             1\n",
      "penguin         1\n",
      "jaguar          1\n",
      "wolf            1\n",
      "fox             1\n",
      "rabbit          1\n",
      "squirrel        1\n",
      "owl             1\n",
      "hawk            1\n",
      "leopard         1\n",
      "eagle           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ordenar por frecuencia en orden descendente\n",
    "sorted_frequency_counts = frequency_counts.sort_values(ascending=False)\n",
    "print(sorted_frequency_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Generar un DataFrame que muestre la frecuencia acumulativa de las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Animal  Cumulative Count\n",
      "0            cat                 3\n",
      "1       elephant                 6\n",
      "2            dog                 9\n",
      "3          panda                12\n",
      "4       kangaroo                15\n",
      "5          zebra                18\n",
      "6        giraffe                21\n",
      "7          koala                24\n",
      "8          tiger                27\n",
      "9           lion                30\n",
      "10          fish                33\n",
      "11          bird                36\n",
      "12          bear                38\n",
      "13        monkey                40\n",
      "14       leopard                41\n",
      "15          hawk                42\n",
      "16           owl                43\n",
      "17           bat                44\n",
      "18      squirrel                45\n",
      "19        rabbit                46\n",
      "20           fox                47\n",
      "21          wolf                48\n",
      "22        jaguar                49\n",
      "23       penguin                50\n",
      "24       cheetah                51\n",
      "25    rhinoceros                52\n",
      "26  hippopotamus                53\n",
      "27     alligator                54\n",
      "28     crocodile                55\n",
      "29       ostrich                56\n",
      "30       dolphin                57\n",
      "31         whale                58\n",
      "32         shark                59\n",
      "33         eagle                60\n"
     ]
    }
   ],
   "source": [
    "# Frecuencia acumulativa\n",
    "cumulative_frequency = frequency_counts.cumsum()\n",
    "cumulative_frequency_df = cumulative_frequency.reset_index()\n",
    "cumulative_frequency_df.columns = ['Animal', 'Cumulative Count']\n",
    "print(cumulative_frequency_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
